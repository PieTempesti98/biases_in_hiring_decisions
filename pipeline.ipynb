{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3f53ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "wanted_topics = ['hiring','hiring decisions','human resources','HR','bias']\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "def get_sorted_dictionary(elements):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    how is the dictionary organised:\n",
    "    \n",
    "    key -> element in the list\n",
    "    value-> number of times the key appears in the list\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dictionary = {}\n",
    "    ret = {}\n",
    "    \n",
    "    dictionary = {element:elements.count(element) for element in elements}\n",
    "            \n",
    "    sorted_dict =  sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_dict\n",
    "\n",
    "def get_k_most_recurring_words(list,k):\n",
    "    counter = 0\n",
    "    \n",
    "    list_of_words = []\n",
    "\n",
    "    for entity in list:\n",
    "        #print(f'{entity[0]} appears {entity[1]} times')\n",
    "        counter += 1\n",
    "        list_of_words.append(entity)\n",
    "        if counter == k:\n",
    "            return list_of_words\n",
    "\n",
    "#checks the number of items wanted_topics and current_topics have in common\n",
    "def get_number_same_topic(current_topics):\n",
    "    \n",
    "    if(len(current_topics) == 0):\n",
    "        return 0;\n",
    "    \n",
    "    return len(set(current_topics) & set(wanted_topics))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd878c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import nltk\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import yake\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from pke.unsupervised import YAKE\n",
    "\n",
    "def remove_stopwords(text,stopwords):\n",
    "    new = []\n",
    "    splitted_text = text.split()\n",
    "    for word in splitted_text:\n",
    "        if word not in stopwords or word.isdigit() or word == 'MIT':\n",
    "            new.append(word)\n",
    "            \n",
    "    return  \" \".join(new)\n",
    "\n",
    "possible_pdfs = []\n",
    "\n",
    "# Folder Path\n",
    "path = \"/Users/benedettatessa/Downloads/pdfs 2\"\n",
    "  \n",
    "# Change the directory\n",
    "os.chdir(path)\n",
    "  \n",
    "# iterate through all files\n",
    "for file in os.listdir():\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_path = f\"{path}/{file}\"\n",
    "        #print(pdf_path)\n",
    "        \n",
    "        pdfFileObject =  open(pdf_path, 'rb')\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObject)\n",
    "        text=''\n",
    "        \n",
    "        #get text from all pages\n",
    "        for i in range(0,pdfReader.numPages):\n",
    "            # creating a page object\n",
    "            pageObj = pdfReader.getPage(i)\n",
    "            # extracting text from page\n",
    "            text=text+pageObj.extractText()\n",
    "\n",
    "\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        stop = stopwords.words('english')\n",
    "        text = remove_stopwords(text,stop)\n",
    "        \n",
    "        extractor = YAKE()\n",
    "        \n",
    "        extractor.load_document(input=text.lower(),\n",
    "                        language='en',\n",
    "                        normalization=None)\n",
    "        \n",
    "        \n",
    "        extractor.candidate_selection(n=2)\n",
    "\n",
    "        # 4. Calculate scores for the candidate keywords\n",
    "        extractor.candidate_weighting(window=2,\n",
    "                                      use_stems=True)\n",
    "\n",
    "        # 5. Select 10 highest ranked keywords\n",
    "        # Remove redundant keywords with similarity above 80%\n",
    "        key_phrases = extractor.get_n_best(n=10, threshold=0.8)\n",
    "        print(key_phrases)\n",
    "        \n",
    "\n",
    "        '''\n",
    "        nlp = spacy.load(\"en_core_web_md\")\n",
    "        stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        tokens = []\n",
    "        tokens_dict = {}\n",
    "        \n",
    "        # Iterate over the tokens \n",
    "        for token in doc:\n",
    "            #include token in our analysis if not a punctuation, not a stopword, not a number\n",
    "            if((not token.is_punct) and (not token.lemma_ in stopwords) and (not token.text.isnumeric())):\n",
    "                tokens.append(token.lemma_ )\n",
    "                \n",
    "        tokens_dict = get_sorted_dictionary(tokens)\n",
    "        recurring = get_k_most_recurring_words(tokens_dict,5)\n",
    "        \n",
    "        common = get_number_same_topic(recurring)\n",
    "        \n",
    "        if not (common == None) and common > 2 : \n",
    "            possible_pdfs.append(file)\n",
    "            print(f'{file} requires a further ananlysis')  \n",
    "        else:\n",
    "            print('useless')\n",
    "        '''\n",
    "        \n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d1c26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08e0cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8e26e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c7143",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}